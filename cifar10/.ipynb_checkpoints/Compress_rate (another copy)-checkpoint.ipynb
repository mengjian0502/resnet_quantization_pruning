{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#                                                                                                                                                                 import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5)\n",
    "b = np.zeros((3,3))\n",
    "c = b.shape\n",
    "c\n",
    "# print(a)\n",
    "# c = a.median()\n",
    "# print(c)\n",
    "# b = a[a>0.0]\n",
    "# print(b)\n",
    "# count = b.numel()\n",
    "# print((count)* 1.0)\n",
    "# c = a.numpy()\n",
    "# b = np.count_nonzero(c)\n",
    "# print(b)\n",
    "# b,c = a.sort()\n",
    "# print(b,c)\n",
    "# indx = c[2:]\n",
    "# print(indx)\n",
    "# d,e = indx.sort()\n",
    "# print(d,e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PE-wise pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.layer1.0.conv1.weight\n",
      "(64, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.layer1.0.conv1.weight filter wise sparsity_mean: 0.127089\t sparsity_min: 0.125000\n",
      "module.layer1.0.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.layer1.0.conv2.weight filter wise sparsity_mean: 0.002333\t sparsity_min: 0.000000\n",
      "module.layer1.1.conv1.weight\n",
      "(64, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.layer1.1.conv1.weight filter wise sparsity_mean: 0.002333\t sparsity_min: 0.000000\n",
      "module.layer1.1.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.layer1.1.conv2.weight filter wise sparsity_mean: 0.002523\t sparsity_min: 0.000000\n",
      "module.layer2.0.conv1.weight\n",
      "(128, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:128\n",
      "module.layer2.0.conv1.weight filter wise sparsity_mean: 0.002143\t sparsity_min: 0.000000\n",
      "module.layer2.0.conv2.weight\n",
      "(256, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:256\n",
      "module.layer2.0.conv2.weight filter wise sparsity_mean: 0.003045\t sparsity_min: 0.000000\n",
      "module.layer2.1.conv1.weight\n",
      "(256, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:256\n",
      "module.layer2.1.conv1.weight filter wise sparsity_mean: 0.002909\t sparsity_min: 0.000000\n",
      "module.layer2.1.conv2.weight\n",
      "(256, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:256\n",
      "module.layer2.1.conv2.weight filter wise sparsity_mean: 0.003669\t sparsity_min: 0.000000\n",
      "module.layer3.0.conv1.weight\n",
      "(512, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:512\n",
      "module.layer3.0.conv1.weight filter wise sparsity_mean: 0.002953\t sparsity_min: 0.000000\n",
      "module.layer3.0.conv2.weight\n",
      "(1024, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:1024\n",
      "module.layer3.0.conv2.weight filter wise sparsity_mean: 0.004423\t sparsity_min: 0.000000\n",
      "module.layer3.1.conv1.weight\n",
      "(1024, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:1024\n",
      "module.layer3.1.conv1.weight filter wise sparsity_mean: 0.005146\t sparsity_min: 0.000000\n",
      "module.layer3.1.conv2.weight\n",
      "(1024, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:1024\n",
      "module.layer3.1.conv2.weight filter wise sparsity_mean: 0.009086\t sparsity_min: 0.000000\n",
      "module.layer4.0.conv1.weight\n",
      "(2048, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:2048\n",
      "module.layer4.0.conv1.weight filter wise sparsity_mean: 0.003728\t sparsity_min: 0.000000\n",
      "module.layer4.0.conv2.weight\n",
      "(4096, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:4096\n",
      "module.layer4.0.conv2.weight filter wise sparsity_mean: 0.006027\t sparsity_min: 0.000000\n",
      "module.layer4.1.conv1.weight\n",
      "(4096, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:4096\n",
      "module.layer4.1.conv1.weight filter wise sparsity_mean: 0.005492\t sparsity_min: 0.000000\n",
      "module.layer4.1.conv2.weight\n",
      "(4096, 64, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:4096\n",
      "module.layer4.1.conv2.weight filter wise sparsity_mean: 0.005780\t sparsity_min: 0.000000\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:1.000000\n",
      "compression rate:64.000000\n",
      "overall sparsity:0.005533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "model = torch.load('./save/new_resnet18/sgd/hc_00005_003_mix_skip/model_best.pth.tar')\n",
    "params = model['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "group_ch = 64\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "tern = False\n",
    "none_zero = 0\n",
    "whole_value = 0\n",
    "for k,v in params.items():\n",
    "\n",
    "    if 'layer' in k and 'conv' in k:\n",
    "        print(k)\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-4] = output[np.absolute(output) > 1e-4]\n",
    "        # ==\n",
    "        \n",
    "        none_zero += np.count_nonzero(out_sparse)\n",
    "        whole_value += cout*cin*kh*kw\n",
    "        \n",
    "        w_t = out_sparse.reshape(cout, cin // group_ch, group_ch, kh, kh)\n",
    "        num_group = (cout * cin) // group_ch\n",
    "        w_t = w_t.reshape(num_group, group_ch, kh, kh)\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 64 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))\n",
    "print('overall sparsity:{:.6f}'.format(((whole_value - none_zero * 1.0)/ (whole_value+1000*512))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "channel-wise pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained model\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "torch.Size([64, 3, 7, 7])\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "filterternConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([128, 64, 3, 3])\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([128, 128, 3, 3])\n",
      "filterternConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "torch.Size([128, 64, 1, 1])\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([128, 128, 3, 3])\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([128, 128, 3, 3])\n",
      "filterternConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([256, 128, 3, 3])\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([256, 256, 3, 3])\n",
      "filterternConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "torch.Size([256, 128, 1, 1])\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([256, 256, 3, 3])\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([256, 256, 3, 3])\n",
      "filterternConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([512, 256, 3, 3])\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([512, 512, 3, 3])\n",
      "filterternConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "torch.Size([512, 256, 1, 1])\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([512, 512, 3, 3])\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([512, 512, 3, 3])\n",
      "Linear(in_features=512, out_features=1000, bias=True)\n",
      "torch.Size([1000, 512])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "from models.ResNet_tern import resnet18b_ff_lf_tex1, resnet18b_fq_lq_tex1\n",
    "\n",
    "\n",
    "net = resnet18b_ff_lf_tex1()\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "model = torch.load('./save/resnet18/30x_model_00008/checkpoint.pth.tar')\n",
    "\n",
    "params = model['state_dict']\n",
    "\n",
    "for k,v in params.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        print(m)\n",
    "        print(m.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of filters:64\n",
      "num of sparse filters:19\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) filter wise sparsity_mean: 0.362457\t sparsity_min: 0.027211\n",
      "num of filters:64\n",
      "num of sparse filters:19\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.487739\t sparsity_min: 0.211806\n",
      "num of filters:64\n",
      "num of sparse filters:19\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.430311\t sparsity_min: 0.137153\n",
      "num of filters:64\n",
      "num of sparse filters:19\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.392090\t sparsity_min: 0.097222\n",
      "num of filters:64\n",
      "num of sparse filters:19\n",
      "filterternConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.495253\t sparsity_min: 0.229167\n",
      "num of filters:128\n",
      "num of sparse filters:38\n",
      "filterternConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.379924\t sparsity_min: 0.072917\n",
      "num of filters:128\n",
      "num of sparse filters:38\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.455967\t sparsity_min: 0.182292\n",
      "num of filters:128\n",
      "num of sparse filters:38\n",
      "filterternConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) filter wise sparsity_mean: 0.335938\t sparsity_min: 0.000000\n",
      "num of filters:128\n",
      "num of sparse filters:38\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.387763\t sparsity_min: 0.097222\n",
      "num of filters:128\n",
      "num of sparse filters:38\n",
      "filterternConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.526699\t sparsity_min: 0.275174\n",
      "num of filters:256\n",
      "num of sparse filters:76\n",
      "filterternConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.383725\t sparsity_min: 0.092014\n",
      "num of filters:256\n",
      "num of sparse filters:76\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.550842\t sparsity_min: 0.321615\n",
      "num of filters:256\n",
      "num of sparse filters:76\n",
      "filterternConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) filter wise sparsity_mean: 0.360748\t sparsity_min: 0.015625\n",
      "num of filters:256\n",
      "num of sparse filters:76\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.481545\t sparsity_min: 0.216580\n",
      "num of filters:256\n",
      "num of sparse filters:76\n",
      "filterternConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.562963\t sparsity_min: 0.325521\n",
      "num of filters:512\n",
      "num of sparse filters:152\n",
      "filterternConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.416374\t sparsity_min: 0.132378\n",
      "num of filters:512\n",
      "num of sparse filters:119\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.578183\t sparsity_min: 0.365451\n",
      "num of filters:512\n",
      "num of sparse filters:152\n",
      "filterternConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) filter wise sparsity_mean: 0.366699\t sparsity_min: 0.042969\n",
      "num of filters:512\n",
      "num of sparse filters:124\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.424900\t sparsity_min: 0.143229\n",
      "num of filters:512\n",
      "num of sparse filters:152\n",
      "filterternConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.461142\t sparsity_min: 0.173828\n",
      "num of filters:1000\n",
      "num of sparse filters:0\n",
      "Linear(in_features=512, out_features=1000, bias=True) filter wise sparsity_mean: 0.375535\t sparsity_min: 0.332031\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.764828\n",
      "compression rate:20.919748\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "# model = torch.load('./save/2019-06-10/cifar10_resnet20_120_swp_alllayer_channelwise/model_best.pth.tar')\n",
    "# params = model['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "tern = False\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = m.weight.data\n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            kh = output.shape[2]\n",
    "            kw = output.shape[3]\n",
    "        else:\n",
    "            kh = 1\n",
    "            kw = 1\n",
    "            \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-2] = output[np.absolute(output) > 1e-2]\n",
    "        # ==\n",
    "        w_t = out_sparse.reshape(cout, cin * kh * kw)\n",
    "        num_group = cout\n",
    "#         print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of filters:{}'.format(cout))\n",
    "\n",
    "        print('num of sparse filters:{}'.format(num_one))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(m, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without tern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:16\n",
      "stage_1.0.conv_a.weight filter wise sparsity_mean: 0.197917\t sparsity_min: 0.131944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:1\n",
      "num of group:16\n",
      "stage_1.0.conv_b.weight filter wise sparsity_mean: 0.101128\t sparsity_min: 0.006944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:3\n",
      "num of group:16\n",
      "stage_1.1.conv_a.weight filter wise sparsity_mean: 0.216580\t sparsity_min: 0.013889\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "stage_1.1.conv_b.weight filter wise sparsity_mean: 0.434896\t sparsity_min: 0.131944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:2\n",
      "num of group:16\n",
      "stage_1.2.conv_a.weight filter wise sparsity_mean: 0.163194\t sparsity_min: 0.006944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "stage_1.2.conv_b.weight filter wise sparsity_mean: 0.396701\t sparsity_min: 0.062500\n",
      "(32, 16, 3, 3)\n",
      "num of sparse group:4\n",
      "num of group:32\n",
      "stage_2.0.conv_a.weight filter wise sparsity_mean: 0.161458\t sparsity_min: 0.000000\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:7\n",
      "num of group:64\n",
      "stage_2.0.conv_b.weight filter wise sparsity_mean: 0.268446\t sparsity_min: 0.069444\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:27\n",
      "num of group:64\n",
      "stage_2.1.conv_a.weight filter wise sparsity_mean: 0.436957\t sparsity_min: 0.006944\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:11\n",
      "num of group:64\n",
      "stage_2.1.conv_b.weight filter wise sparsity_mean: 0.241428\t sparsity_min: 0.013889\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:10\n",
      "num of group:64\n",
      "stage_2.2.conv_a.weight filter wise sparsity_mean: 0.305556\t sparsity_min: 0.006944\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:21\n",
      "num of group:64\n",
      "stage_2.2.conv_b.weight filter wise sparsity_mean: 0.373264\t sparsity_min: 0.006944\n",
      "(128, 16, 3, 3)\n",
      "num of sparse group:26\n",
      "num of group:128\n",
      "stage_3.0.conv_a.weight filter wise sparsity_mean: 0.317491\t sparsity_min: 0.000000\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:80\n",
      "num of group:256\n",
      "stage_3.0.conv_b.weight filter wise sparsity_mean: 0.383219\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:72\n",
      "num of group:256\n",
      "stage_3.1.conv_a.weight filter wise sparsity_mean: 0.370361\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:105\n",
      "num of group:256\n",
      "stage_3.1.conv_b.weight filter wise sparsity_mean: 0.477648\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:81\n",
      "num of group:256\n",
      "stage_3.2.conv_a.weight filter wise sparsity_mean: 0.371745\t sparsity_min: 0.000000\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:114\n",
      "num of group:256\n",
      "stage_3.2.conv_b.weight filter wise sparsity_mean: 0.628309\t sparsity_min: 0.159722\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.690733\n",
      "compression rate:23.163807\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "model = torch.load('./save/2019-05-29/cifar10_resnet20_120_base_swp_0002/checkpoint.pth.tar')\n",
    "params = model['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "group_ch = 16\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "tern = False\n",
    "\n",
    "for k,v in params.items():\n",
    "#     print(k)\n",
    "    if 'stage' in k and 'conv' in k:\n",
    "#     if 'layer' in k and 'conv' in k:\n",
    "#         print(v)\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-3] = output[np.absolute(output) > 1e-3]\n",
    "        # ==\n",
    "        \n",
    "        w_t = out_sparse.reshape(cout, cin // group_ch, group_ch, 3, 3)\n",
    "        num_group = (cout * cin) // group_ch\n",
    "        w_t = w_t.reshape(num_group, group_ch, 3, 3)\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3, 3)\n",
      "num of sparse group:50\n",
      "num of group:128\n",
      "module.chained_blocks.0.dw_conv.weight filter wise sparsity_mean: 0.551215\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:1\n",
      "num of group:64\n",
      "module.chained_blocks.0.pw_conv.weight filter wise sparsity_mean: 0.649170\t sparsity_min: 0.398438\n",
      "(128, 3, 3)\n",
      "num of sparse group:10\n",
      "num of group:128\n",
      "module.chained_blocks.1.dw_conv.weight filter wise sparsity_mean: 0.379340\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.chained_blocks.1.pw_conv.weight filter wise sparsity_mean: 0.460327\t sparsity_min: 0.273438\n",
      "(128, 3, 3)\n",
      "num of sparse group:1\n",
      "num of group:128\n",
      "module.chained_blocks.2.dw_conv.weight filter wise sparsity_mean: 0.333333\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.chained_blocks.2.pw_conv.weight filter wise sparsity_mean: 0.399780\t sparsity_min: 0.171875\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.892361\n",
      "compression rate:17.929961\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('./save/2019-05-12/mnist_bd_net_100_mnist_tt_32_bs256_m2_128_d3_newlr_th005_drop1_swp00005/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-12/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_swp00002/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_swp00001/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_newswp00001/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_newswp00005_finetune/checkpoint.pth.tar')\n",
    "checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr005_drop1_newswp00002_05mean_finetune/checkpoint.pth.tar')\n",
    "\n",
    "params = checkpoint['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "\n",
    "for k,v in params.items():\n",
    "#     print(k)\n",
    "    if \"dw_conv.weight\" in k:\n",
    "        tern = True\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-5] = output[np.absolute(output) > 1e-5]\n",
    "        # ==\n",
    "        \n",
    "        w_t = np.array(out_sparse)\n",
    "        num_group = w_t.shape[0]\n",
    "        w_t = w_t.reshape(num_group, 3, 3)\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "#             print(w_t[i])\n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "    if \"pw_conv.weight\" in k:\n",
    "        tern = True\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-3] = output[np.absolute(output) > 1e-3]\n",
    "        # ==\n",
    "        \n",
    "        w_t = np.array(out_sparse)\n",
    "        num_group = w_t.shape[0]\n",
    "        w_t = w_t.reshape(num_group, w_t.shape[1])\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "#             print(w_t[i])\n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
