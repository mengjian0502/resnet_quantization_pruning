{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#                                                                                                                                                                 import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "channel-wise pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarResNet : Depth : 20 , Layers for each block : 3\n",
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 3, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([16, 16, 3, 3])\n",
      "Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 16, 3, 3])\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 32, 3, 3])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Linear(in_features=64, out_features=10, bias=True)\n",
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "from models.vanilla_resnet_cifar import resnet20\n",
    "from models.adptive_resnet_cifar_recy import adp_resnet20_rec\n",
    "from models.mobilenet_v2 import mobilenetv2\n",
    "\n",
    "net = resnet20()\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "# model = torch.load('./save/2019-06-12/cifar10_resnet20_120_swp_alllayer_channelwise_rank05_0005/checkpoint.pth.tar')\n",
    "model = torch.load('./save/2019-06-10/cifar10_resnet20_120_swp_alllayer_channelwise_0003/model_best.pth.tar')\n",
    "\n",
    "params = model['state_dict']\n",
    "\n",
    "# for k,v in params.items():\n",
    "#     name = k[7:]\n",
    "#     new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(params)\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        print(m)\n",
    "        print(m.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 27)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.365741\t sparsity_min: 0.000000\n",
      "(16, 144)\n",
      "num of sparse group:4\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.526042\t sparsity_min: 0.312500\n",
      "(16, 144)\n",
      "num of sparse group:6\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.541667\t sparsity_min: 0.250000\n",
      "(16, 144)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.427951\t sparsity_min: 0.104167\n",
      "(16, 144)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.546007\t sparsity_min: 0.319444\n",
      "(16, 144)\n",
      "num of sparse group:2\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.168403\t sparsity_min: 0.000000\n",
      "(16, 144)\n",
      "num of sparse group:6\n",
      "num of group:16\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.470486\t sparsity_min: 0.125000\n",
      "(32, 144)\n",
      "num of sparse group:6\n",
      "num of group:32\n",
      "Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.229384\t sparsity_min: 0.006944\n",
      "(32, 288)\n",
      "num of sparse group:7\n",
      "num of group:32\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.366102\t sparsity_min: 0.166667\n",
      "(32, 288)\n",
      "num of sparse group:5\n",
      "num of group:32\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.274197\t sparsity_min: 0.114583\n",
      "(32, 288)\n",
      "num of sparse group:10\n",
      "num of group:32\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.444987\t sparsity_min: 0.149306\n",
      "(32, 288)\n",
      "num of sparse group:7\n",
      "num of group:32\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.249023\t sparsity_min: 0.013889\n",
      "(32, 288)\n",
      "num of sparse group:11\n",
      "num of group:32\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.514974\t sparsity_min: 0.236111\n",
      "(64, 288)\n",
      "num of sparse group:12\n",
      "num of group:64\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.235569\t sparsity_min: 0.027778\n",
      "(64, 576)\n",
      "num of sparse group:13\n",
      "num of group:64\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.384956\t sparsity_min: 0.203125\n",
      "(64, 576)\n",
      "num of sparse group:8\n",
      "num of group:64\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.201470\t sparsity_min: 0.065972\n",
      "(64, 576)\n",
      "num of sparse group:26\n",
      "num of group:64\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.503554\t sparsity_min: 0.138889\n",
      "(64, 576)\n",
      "num of sparse group:17\n",
      "num of group:64\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.297472\t sparsity_min: 0.019097\n",
      "(64, 576)\n",
      "num of sparse group:15\n",
      "num of group:64\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) filter wise sparsity_mean: 0.554905\t sparsity_min: 0.296875\n",
      "(10, 64)\n",
      "num of sparse group:0\n",
      "num of group:10\n",
      "Linear(in_features=64, out_features=10, bias=True) filter wise sparsity_mean: 0.020313\t sparsity_min: 0.000000\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.756447\n",
      "compression rate:21.151515\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "# model = torch.load('./save/2019-06-10/cifar10_resnet20_120_swp_alllayer_channelwise/model_best.pth.tar')\n",
    "# params = model['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "tern = False\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = m.weight.data\n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            kh = output.shape[2]\n",
    "            kw = output.shape[3]\n",
    "        else:\n",
    "            kh = 1\n",
    "            kw = 1\n",
    "            \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-3] = output[np.absolute(output) > 1e-3]\n",
    "        # ==\n",
    "        w_t = out_sparse.reshape(cout, cin * kh * kw)\n",
    "        num_group = cout\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(m, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without tern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 3, 3)\n",
      "num of sparse group:0\n",
      "num of group:16\n",
      "stage_1.0.conv_a.weight filter wise sparsity_mean: 0.197917\t sparsity_min: 0.131944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:1\n",
      "num of group:16\n",
      "stage_1.0.conv_b.weight filter wise sparsity_mean: 0.101128\t sparsity_min: 0.006944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:3\n",
      "num of group:16\n",
      "stage_1.1.conv_a.weight filter wise sparsity_mean: 0.216580\t sparsity_min: 0.013889\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "stage_1.1.conv_b.weight filter wise sparsity_mean: 0.434896\t sparsity_min: 0.131944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:2\n",
      "num of group:16\n",
      "stage_1.2.conv_a.weight filter wise sparsity_mean: 0.163194\t sparsity_min: 0.006944\n",
      "(16, 16, 3, 3)\n",
      "num of sparse group:5\n",
      "num of group:16\n",
      "stage_1.2.conv_b.weight filter wise sparsity_mean: 0.396701\t sparsity_min: 0.062500\n",
      "(32, 16, 3, 3)\n",
      "num of sparse group:4\n",
      "num of group:32\n",
      "stage_2.0.conv_a.weight filter wise sparsity_mean: 0.161458\t sparsity_min: 0.000000\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:7\n",
      "num of group:64\n",
      "stage_2.0.conv_b.weight filter wise sparsity_mean: 0.268446\t sparsity_min: 0.069444\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:27\n",
      "num of group:64\n",
      "stage_2.1.conv_a.weight filter wise sparsity_mean: 0.436957\t sparsity_min: 0.006944\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:11\n",
      "num of group:64\n",
      "stage_2.1.conv_b.weight filter wise sparsity_mean: 0.241428\t sparsity_min: 0.013889\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:10\n",
      "num of group:64\n",
      "stage_2.2.conv_a.weight filter wise sparsity_mean: 0.305556\t sparsity_min: 0.006944\n",
      "(64, 16, 3, 3)\n",
      "num of sparse group:21\n",
      "num of group:64\n",
      "stage_2.2.conv_b.weight filter wise sparsity_mean: 0.373264\t sparsity_min: 0.006944\n",
      "(128, 16, 3, 3)\n",
      "num of sparse group:26\n",
      "num of group:128\n",
      "stage_3.0.conv_a.weight filter wise sparsity_mean: 0.317491\t sparsity_min: 0.000000\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:80\n",
      "num of group:256\n",
      "stage_3.0.conv_b.weight filter wise sparsity_mean: 0.383219\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:72\n",
      "num of group:256\n",
      "stage_3.1.conv_a.weight filter wise sparsity_mean: 0.370361\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:105\n",
      "num of group:256\n",
      "stage_3.1.conv_b.weight filter wise sparsity_mean: 0.477648\t sparsity_min: 0.006944\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:81\n",
      "num of group:256\n",
      "stage_3.2.conv_a.weight filter wise sparsity_mean: 0.371745\t sparsity_min: 0.000000\n",
      "(256, 16, 3, 3)\n",
      "num of sparse group:114\n",
      "num of group:256\n",
      "stage_3.2.conv_b.weight filter wise sparsity_mean: 0.628309\t sparsity_min: 0.159722\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.690733\n",
      "compression rate:23.163807\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "model = torch.load('./save/2019-05-29/cifar10_resnet20_120_base_swp_0002/checkpoint.pth.tar')\n",
    "params = model['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "group_ch = 16\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "tern = False\n",
    "\n",
    "for k,v in params.items():\n",
    "#     print(k)\n",
    "    if 'stage' in k and 'conv' in k:\n",
    "#     if 'layer' in k and 'conv' in k:\n",
    "#         print(v)\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-3] = output[np.absolute(output) > 1e-3]\n",
    "        # ==\n",
    "        \n",
    "        w_t = out_sparse.reshape(cout, cin // group_ch, group_ch, 3, 3)\n",
    "        num_group = (cout * cin) // group_ch\n",
    "        w_t = w_t.reshape(num_group, group_ch, 3, 3)\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3, 3)\n",
      "num of sparse group:50\n",
      "num of group:128\n",
      "module.chained_blocks.0.dw_conv.weight filter wise sparsity_mean: 0.551215\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:1\n",
      "num of group:64\n",
      "module.chained_blocks.0.pw_conv.weight filter wise sparsity_mean: 0.649170\t sparsity_min: 0.398438\n",
      "(128, 3, 3)\n",
      "num of sparse group:10\n",
      "num of group:128\n",
      "module.chained_blocks.1.dw_conv.weight filter wise sparsity_mean: 0.379340\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.chained_blocks.1.pw_conv.weight filter wise sparsity_mean: 0.460327\t sparsity_min: 0.273438\n",
      "(128, 3, 3)\n",
      "num of sparse group:1\n",
      "num of group:128\n",
      "module.chained_blocks.2.dw_conv.weight filter wise sparsity_mean: 0.333333\t sparsity_min: 0.000000\n",
      "(64, 128)\n",
      "num of sparse group:0\n",
      "num of group:64\n",
      "module.chained_blocks.2.pw_conv.weight filter wise sparsity_mean: 0.399780\t sparsity_min: 0.171875\n",
      "==== conclusion ==== \n",
      "all_sparsity_min:0.000000\n",
      "group density for all layer:0.892361\n",
      "compression rate:17.929961\n"
     ]
    }
   ],
   "source": [
    "def weight_tern(fp_w, t_factor):\n",
    "    fp_w = torch.from_numpy(fp_w)\n",
    "    mean_w = fp_w.abs().mean()\n",
    "    max_w = fp_w.abs().max()\n",
    "    th = t_factor*max_w\n",
    "\n",
    "    output = fp_w.clone().zero_()\n",
    "    W = fp_w[fp_w.ge(th)+fp_w.le(-th)].abs().mean()\n",
    "    output[fp_w.ge(th)] = 1\n",
    "    output[fp_w.lt(-th)] = -1\n",
    "#     print('W:{}'.format(W))\n",
    "    return output.numpy()\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('./save/2019-05-12/mnist_bd_net_100_mnist_tt_32_bs256_m2_128_d3_newlr_th005_drop1_swp00005/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-12/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_swp00002/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_swp00001/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_newswp00001/model_best.pth.tar')\n",
    "# checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr_drop1_newswp00005_finetune/checkpoint.pth.tar')\n",
    "checkpoint = torch.load('./save/2019-05-13/svhn_bd_net_100_svhn_tt_32_bs256_m2_256_64_d3_newlr005_drop1_newswp00002_05mean_finetune/checkpoint.pth.tar')\n",
    "\n",
    "params = checkpoint['state_dict']\n",
    "\n",
    "counter = 0\n",
    "overall = 0\n",
    "num_one = 0\n",
    "all_num_one = 0.0\n",
    "all_num_group = 0.0\n",
    "all_sparsity_mean = 0.0\n",
    "all_sparsity_min = 1.0\n",
    "\n",
    "t_factor = 0.05\n",
    "\n",
    "for k,v in params.items():\n",
    "#     print(k)\n",
    "    if \"dw_conv.weight\" in k:\n",
    "        tern = True\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-5] = output[np.absolute(output) > 1e-5]\n",
    "        # ==\n",
    "        \n",
    "        w_t = np.array(out_sparse)\n",
    "        num_group = w_t.shape[0]\n",
    "        w_t = w_t.reshape(num_group, 3, 3)\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "#             print(w_t[i])\n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "    if \"pw_conv.weight\" in k:\n",
    "        tern = True\n",
    "\n",
    "        counter += 1\n",
    "        conv_w = v \n",
    "        output = np.array(conv_w)\n",
    "        cout = output.shape[0]\n",
    "        cin = output.shape[1]\n",
    "        kh = output.shape[2]\n",
    "        kw = output.shape[3]\n",
    "        \n",
    "        if tern:\n",
    "            out_sparse = weight_tern(output, t_factor)\n",
    "        else:\n",
    "        # == set threshold for weight\n",
    "            out_sparse = np.zeros(output.shape)\n",
    "            out_sparse[np.absolute(output) > 1e-3] = output[np.absolute(output) > 1e-3]\n",
    "        # ==\n",
    "        \n",
    "        w_t = np.array(out_sparse)\n",
    "        num_group = w_t.shape[0]\n",
    "        w_t = w_t.reshape(num_group, w_t.shape[1])\n",
    "        print(w_t.shape)\n",
    "        all_num_group += num_group\n",
    "        sparsity_chall = np.zeros(num_group)\n",
    "        num_one = 0\n",
    "        for i in range(num_group):       \n",
    "#             print(w_t[i])\n",
    "            sparsity_group = 1.0*(w_t[i].size - np.count_nonzero(w_t[i]))/w_t[i].size\n",
    "            sparsity_chall[i] = sparsity_group\n",
    "#             print('group wise {} sparsity: {:.8f}'.format(i, sparsity_group))\n",
    "            if np.count_nonzero(w_t[i]) is 0:\n",
    "                num_one += 1\n",
    "        all_num_one += num_one \n",
    "        print('num of sparse group:{}'.format(num_one))\n",
    "        print('num of group:{}'.format(num_group))\n",
    "        \n",
    "        #sparsity mean and min\n",
    "        sparsity_mean = np.mean(sparsity_chall)\n",
    "        sparsity_min = np.min(sparsity_chall[sparsity_chall < 1.0])\n",
    "        all_sparsity_mean += sparsity_mean\n",
    "        if sparsity_min < all_sparsity_min:\n",
    "            all_sparsity_min = sparsity_min\n",
    "        print('{} filter wise sparsity_mean: {:.6f}\\t sparsity_min: {:.6f}'.format(k, sparsity_mean, sparsity_min))\n",
    "\n",
    "print(\"==== conclusion ==== \")\n",
    "print('all_sparsity_min:{:.6f}'.format(all_sparsity_min))\n",
    "density = 1 - all_num_one/all_num_group\n",
    "print('group density for all layer:{:.6f}'.format(1 - all_num_one/all_num_group))\n",
    "cp_r = 16 / ((density)*(1.0 - all_sparsity_min))\n",
    "print('compression rate:{:.6f}'.format(cp_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
